{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data and  Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "labels = list(df_train.columns[2:])\n",
    "df_labels = df_train[labels].copy()\n",
    "\n",
    "print('Training labels:')\n",
    "print(df_labels.columns)\n",
    "print(df_labels.shape) #six labels\n",
    "\n",
    "print('\\nTraining data:')\n",
    "df_train.drop(list(df_labels.columns),inplace=True, axis=1)\n",
    "df_train.drop('id',inplace=True,axis=1)\n",
    "print(list(df_train.columns))\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "print(df_test.columns)\n",
    "print(df_test.shape) #six labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://jayspeidell.github.io/portfolio/project05-toxic-comments/\n",
    "def caps(s):\n",
    "    isalpha = (sum([1 for c in s if c.isalpha()]))\n",
    "    if isalpha == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum([1 for c in s if c.isupper()])/isalpha\n",
    "def word_length(s):\n",
    "    if len(s) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        s = s.split(' ')\n",
    "        return np.mean([len(x) for x in s if x.isalpha()])\n",
    "def strip_ip(s):\n",
    "    temp = ip.search(s)\n",
    "    if temp:\n",
    "        return s.replace(temp.group(),' ')\n",
    "    return s\n",
    "def extract_features(df_train):\n",
    "    df_train['length'] = df_train.comment_text.apply(lambda x: len(str(x))) # the length of the comments\n",
    "    df_train['caps'] = df_train.comment_text.apply(lambda x: caps(str(x))) # the capitalization percent\n",
    "    #df_train['word_length'] = df_train.comment_text.apply(lambda x: word_length(str(x)))# the average word length\n",
    "    df_train['exclamation'] = df_train.comment_text.apply(lambda s: len([c for c in str(s) if c == '!']))# the average number of exclamation points\n",
    "    df_train['question'] = df_train.comment_text.apply(lambda s: len([c for c in str(s) if c == '?']))# the average number of question marks\n",
    "    #Normalization\n",
    "    for feature in ['length','caps','word_length','exclamation','question']:\n",
    "        diff  = max(df_train[feature]) - min(df_train[feature])\n",
    "        df_train[feature] = df_train[feature].apply(lambda x: (x-min(df_train[feature]))/diff)\n",
    "    ip = re.compile('(([2][5][0-5]\\.)|([2][0-4][0-9]\\.)|([0-1]?[0-9]?[0-9]\\.)){3}'\n",
    "                    +'(([2][5][0-5])|([2][0-4][0-9])|([0-1]?[0-9]?[0-9]))')\n",
    "    df_train['comment_text'] = df_train.comment_text.apply(lambda x: strip_ip(x,ip))\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = extract_features(df_train)\n",
    "print(list(df_train.columns))\n",
    "df_test = extract_features(df_test)\n",
    "print(list(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "comment_vector = TfidfVectorizer(max_features=10000, analyzer='word', stop_words='english')\n",
    "training_comments = comment_vector.fit_transform(df_train[comment_text])\n",
    "testing_comments = comment_vector.fit_transform(df_test[comment_text])\n",
    "print(time)\n",
    "print(training_comments)\n",
    "print(testing_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    lr = LogisticRegression(random_state = 42)\n",
    "    print(label + ' score: %.4f' % np.mean(cross_val_score(lr, training_comments, df_labels[label], scoring='f1', cv=cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=1.0)\n",
    "_ = multi_cv(model, training_comments, df_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=seed)\n",
    "_ = multi_cv(model, training_comments, df_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
