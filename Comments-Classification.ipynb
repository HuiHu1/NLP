{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data and  Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels:\n",
      "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
      "       'identity_hate'],\n",
      "      dtype='object')\n",
      "(155054, 6)\n",
      "\n",
      "Training data:\n",
      "['comment_text']\n",
      "(155054, 1)\n",
      "Index(['id', 'comment_text'], dtype='object')\n",
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "labels = list(df_train.columns[2:])\n",
    "df_labels = df_train[labels].copy()\n",
    "\n",
    "print('Training labels:')\n",
    "print(df_labels.columns)\n",
    "print(df_labels.shape) #six labels\n",
    "\n",
    "print('\\nTraining data:')\n",
    "df_train.drop(list(df_labels.columns),inplace=True, axis=1)\n",
    "df_train.drop('id',inplace=True,axis=1)\n",
    "print(list(df_train.columns))\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "print(df_test.columns)\n",
    "print(df_test.shape) #six labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://jayspeidell.github.io/portfolio/project05-toxic-comments/\n",
    "def caps(s):\n",
    "    return sum([1 for c in s if c.isupper()])/(sum([1 for c in s if c.isalpha()]))\n",
    "\n",
    "def word_length(s):\n",
    "    s = s.split(' ')\n",
    "    return np.mean([len(x) for x in s if x.isalpha()])\n",
    "\n",
    "def strip_ip(s):\n",
    "    temp = ip.search(s)\n",
    "    if temp:\n",
    "        return s.replace(temp.group(),' ')\n",
    "    return s\n",
    "\n",
    "def extract_features(df):\n",
    "    df_train['length'] = df_train.comment_text.apply(lambda x: len(x)) # the length of the comments\n",
    "    df_train['caps'] = df_train.comment_text.apply(lambda x: caps(x)) # the capitalization percent\n",
    "    df_train['word_length'] = df_train.comment_text.apply(lambda x: word_length(x))# the average word length\n",
    "    df_train['exclamation'] = df_train.comment_text.apply(lambda s: len([c for c in s if c == '!']))# the average number of exclamation points\n",
    "    df_train['question'] = df_train.comment_text.apply(lambda s: len([c for c in s if c == '?']))# the average number of question marks\n",
    "    #Normalization\n",
    "    for feature in ['length','caps','word_length','exclamation','question']:\n",
    "        diff  = max(df_train[feature]) - min(df_train[feature])\n",
    "        dif[feature] = df[feature].apply(lambda x: (x-min(df_train[feature]))/diff)\n",
    "    \n",
    "    ip = re.compile('(([2][5][0-5]\\.)|([2][0-4][0-9]\\.)|([0-1]?[0-9]?[0-9]\\.)){3}'\n",
    "                    +'(([2][5][0-5])|([2][0-4][0-9])|([0-1]?[0-9]?[0-9]))')\n",
    "    df_train['comment_text'] = df_train.comment_text.apply(lambda x: strip_ip(x,ip))\n",
    "    return df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
